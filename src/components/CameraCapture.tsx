import React, { useRef, useEffect, useState, useCallback } from 'react';
import { RGBData } from '../App';
import { processImageForRGB } from '../utils/opencvProcessor';
import './CameraCapture.css';

interface CameraCaptureProps {
  isActive: boolean;
  onCameraToggle: (active: boolean) => void;
  onRGBDetected: (rgbData: RGBData) => void;
  detectionSettings: {
    edgeThreshold1: number;
    edgeThreshold2: number;
    minArea: number;
    blurKernel: number;
    enableEdgeDetection: boolean;
    enableColorDetection: boolean;
    enableDetailedLogs: boolean;
  };
}

const CameraCapture: React.FC<CameraCaptureProps> = ({
  isActive,
  onCameraToggle,
  onRGBDetected,
  detectionSettings
}) => {
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const animationFrameRef = useRef<number>();
  const [error, setError] = useState<string>('');
  const [isProcessing, setIsProcessing] = useState(false);
  const lastProcessTime = useRef<number>(0);
  const lastFrameData = useRef<ImageData | null>(null);
  const frameChangeThreshold = useRef<number>(0.1); // 10% çš„åƒç´ è®ŠåŒ–é–¾å€¼

  // Log å‡½æ•¸ï¼Œæ ¹æ“šè¨­å®šæ±ºå®šæ˜¯å¦è¼¸å‡º
  const log = (message: string, ...args: any[]) => {
    if (detectionSettings.enableDetailedLogs) {
      console.log(message, ...args);
    }
  };

  // æª¢æ¸¬ç•«é¢è®Šå‹•
  const detectFrameChange = (currentFrame: ImageData, lastFrame: ImageData | null): boolean => {
    if (!lastFrame) {
      log('ğŸ†• é¦–æ¬¡å½±æ ¼ï¼Œéœ€è¦æª¢æ¸¬');
      return true;
    }

    const currentData = currentFrame.data;
    const lastData = lastFrame.data;
    const totalPixels = currentData.length / 4; // RGBA 4å€‹é€šé“
    let changedPixels = 0;

    // å–æ¨£æª¢æ¸¬ï¼ˆæ¯10å€‹åƒç´ æª¢æ¸¬ä¸€æ¬¡ï¼Œæé«˜æ•ˆç‡ï¼‰
    for (let i = 0; i < currentData.length; i += 40) { // æ¯10å€‹åƒç´ æª¢æ¸¬ä¸€æ¬¡
      const r1 = currentData[i];
      const g1 = currentData[i + 1];
      const b1 = currentData[i + 2];
      
      const r2 = lastData[i];
      const g2 = lastData[i + 1];
      const b2 = lastData[i + 2];
      
      // è¨ˆç®—é¡è‰²å·®ç•°
      const colorDiff = Math.abs(r1 - r2) + Math.abs(g1 - g2) + Math.abs(b1 - b2);
      if (colorDiff > 30) { // é¡è‰²å·®ç•°é–¾å€¼
        changedPixels++;
      }
    }

    const changeRatio = changedPixels / (totalPixels / 10);
    log(`ğŸ“Š ç•«é¢è®ŠåŒ–ç‡: ${(changeRatio * 100).toFixed(1)}%`);
    
    return changeRatio > frameChangeThreshold.current;
  };

  // åˆå§‹åŒ–æ”å½±æ©Ÿ
  const initializeCamera = useCallback(async () => {
    try {
      setError('');
      
      // è«‹æ±‚æ”å½±æ©Ÿæ¬Šé™
      const stream = await navigator.mediaDevices.getUserMedia({
        video: {
          facingMode: 'environment', // å¾Œç½®æ”å½±æ©Ÿ
          width: { ideal: 1280, min: 640 },
          height: { ideal: 720, min: 480 },
          frameRate: { ideal: 30, min: 15 }
        },
        audio: false
      });

      if (videoRef.current) {
        videoRef.current.srcObject = stream;
        streamRef.current = stream;
        
        // ç­‰å¾…å½±ç‰‡è¼‰å…¥
        await new Promise((resolve) => {
          if (videoRef.current) {
            videoRef.current.onloadedmetadata = resolve;
          }
        });
        
        log('ğŸ“· æ”å½±æ©Ÿåˆå§‹åŒ–å®Œæˆï¼Œè¨­å®šç‹€æ…‹ç‚º true');
        onCameraToggle(true);
        
        // ç­‰å¾…ç‹€æ…‹æ›´æ–°å¾Œå†é–‹å§‹è™•ç†
        setTimeout(() => {
          log('ğŸ“· æ”å½±æ©Ÿç‹€æ…‹å·²æ›´æ–°ï¼Œé–‹å§‹è™•ç†');
          startProcessing();
        }, 100);
      }
    } catch (err) {
      console.error('æ”å½±æ©Ÿåˆå§‹åŒ–å¤±æ•—:', err);
      setError('ç„¡æ³•å­˜å–æ”å½±æ©Ÿï¼Œè«‹ç¢ºèªå·²æˆäºˆæ”å½±æ©Ÿæ¬Šé™');
      onCameraToggle(false);
    }
  }, [onCameraToggle]);

  // åœæ­¢æ”å½±æ©Ÿ
  const stopCamera = useCallback(() => {
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      streamRef.current = null;
    }
    
    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current);
    }
    
    if (videoRef.current) {
      videoRef.current.srcObject = null;
    }
    
    onCameraToggle(false);
    setIsProcessing(false);
  }, [onCameraToggle]);

  // é–‹å§‹åœ–åƒè™•ç†
  const startProcessing = useCallback(() => {
    console.log('ğŸ” startProcessing è¢«èª¿ç”¨ï¼ŒisActive:', isActive);
    if (!videoRef.current || !canvasRef.current) {
      console.log('âŒ ç„¡æ³•é–‹å§‹è™•ç†ï¼švideo æˆ– canvas ä¸å­˜åœ¨');
      return;
    }
    
    console.log('ğŸš€ é–‹å§‹åœ–åƒè™•ç†å¾ªç’°ï¼ŒisActive:', isActive);
    setIsProcessing(true);
    
    let frameCount = 0;
    const processFrame = async () => {
      // ç›´æ¥æª¢æŸ¥æ”å½±æ©Ÿç‹€æ…‹ï¼Œä¸ä¾è³´ isActive
      const isCameraReady = videoRef.current && canvasRef.current && streamRef.current;
      log('ğŸ”„ processFrame è¢«èª¿ç”¨ï¼Œæ”å½±æ©Ÿå°±ç·’:', isCameraReady);
      
      if (!isCameraReady) {
        console.log('âŒ åœæ­¢è™•ç†ï¼šæ”å½±æ©Ÿæœªå°±ç·’');
        setIsProcessing(false);
        return;
      }

      // é™åˆ¶è™•ç†é »ç‡ï¼Œæ¯ 500ms è™•ç†ä¸€æ¬¡ï¼ˆé™ä½é »ç‡ï¼‰
      const now = Date.now();
      if (now - lastProcessTime.current < 500) {
        log('â±ï¸ è·³éè™•ç†ï¼Œç­‰å¾…æ™‚é–“æœªåˆ°');
        animationFrameRef.current = requestAnimationFrame(processFrame);
        return;
      }
      lastProcessTime.current = now;
      
      frameCount++;
      log('ğŸ“¹ è™•ç†å½±æ ¼ #' + frameCount, new Date().toLocaleTimeString());

      try {
        const canvas = canvasRef.current;
        const video = videoRef.current;
        const ctx = canvas.getContext('2d');
        
        if (!ctx) return;

        // è¨­å®šç•«å¸ƒå°ºå¯¸
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        log('ğŸ“ ç•«å¸ƒå°ºå¯¸è¨­å®šç‚º:', canvas.width, 'x', canvas.height);

        // ç¹ªè£½ç•¶å‰å½±æ ¼
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
        log('ğŸ–¼ï¸ å½±æ ¼ç¹ªè£½å®Œæˆ');
        
        // æª¢æ¸¬ç•«é¢è®Šå‹•
        const currentFrameData = ctx.getImageData(0, 0, canvas.width, canvas.height);
        const hasSignificantChange = detectFrameChange(currentFrameData, lastFrameData.current);
        lastFrameData.current = currentFrameData;
        
        if (!hasSignificantChange) {
          log('ğŸ˜´ ç•«é¢ç„¡é¡¯è‘—è®ŠåŒ–ï¼Œè·³éæª¢æ¸¬');
          // ç¹¼çºŒè™•ç†ä¸‹ä¸€å¹€
          animationFrameRef.current = requestAnimationFrame(processFrame);
          return;
        }
        
        log('ğŸ”„ ç•«é¢æœ‰é¡¯è‘—è®ŠåŒ–ï¼Œé–‹å§‹æª¢æ¸¬');
        
        // ç¹ªè£½æª¢æ¸¬æ¡†ï¼ˆä¸­å¿ƒé»ï¼‰
        const centerX = canvas.width / 2;
        const centerY = canvas.height / 2;
        const radius = Math.min(canvas.width, canvas.height) / 4;
        
        ctx.strokeStyle = '#00ff00';
        ctx.lineWidth = 3;
        ctx.beginPath();
        ctx.arc(centerX, centerY, radius, 0, 2 * Math.PI);
        ctx.stroke();
        
        // ç¹ªè£½åå­—ç·š
        ctx.strokeStyle = '#ff0000';
        ctx.lineWidth = 2;
        ctx.beginPath();
        ctx.moveTo(centerX - 20, centerY);
        ctx.lineTo(centerX + 20, centerY);
        ctx.moveTo(centerX, centerY - 20);
        ctx.lineTo(centerX, centerY + 20);
        ctx.stroke();
        
        log('ğŸ¯ æª¢æ¸¬æ¡†å·²ç¹ªè£½');

        // ä½¿ç”¨ OpenCV è™•ç†åœ–åƒ
        log('ğŸ”§ èª¿ç”¨ OpenCV è™•ç†å‡½æ•¸...');
        const rgbData = await processImageForRGB(
          canvas,
          detectionSettings
        );

        if (rgbData) {
          log('âœ… æª¢æ¸¬åˆ° RGB æ•¸æ“š:', rgbData.hex);
          onRGBDetected(rgbData);
        } else {
          log('âŒ æœªæª¢æ¸¬åˆ° RGB æ•¸æ“š');
        }

        // ç¹¼çºŒè™•ç†ä¸‹ä¸€å¹€
        log('â¡ï¸ æº–å‚™è™•ç†ä¸‹ä¸€å¹€');
        animationFrameRef.current = requestAnimationFrame(processFrame);
      } catch (err) {
        console.error('âŒ åœ–åƒè™•ç†éŒ¯èª¤:', err);
        setIsProcessing(false);
      }
    };

    log('ğŸ¬ é–‹å§‹ç¬¬ä¸€å¹€è™•ç†');
    processFrame();
  }, [isActive, onCameraToggle, detectionSettings.enableDetailedLogs, onRGBDetected]);

  // è™•ç†æ”å½±æ©Ÿç‹€æ…‹è®ŠåŒ–
  useEffect(() => {
    console.log('ğŸ”„ useEffect è§¸ç™¼ï¼ŒisActive:', isActive, 'streamRef.current:', !!streamRef.current);
    if (isActive && !streamRef.current) {
      console.log('ğŸš€ å•Ÿå‹•æ”å½±æ©Ÿ...');
      initializeCamera();
    } else if (!isActive && streamRef.current) {
      console.log('ğŸ›‘ åœæ­¢æ”å½±æ©Ÿ...');
      stopCamera();
    }
  }, [isActive, initializeCamera, stopCamera]);

  // æ¸…ç†è³‡æº
  useEffect(() => {
    return () => {
      stopCamera();
    };
  }, [stopCamera]);

  return (
    <div className="camera-capture">
      <div className="camera-controls">
        <button
          className={`camera-toggle ${isActive ? 'active' : ''}`}
          onClick={() => onCameraToggle(!isActive)}
        >
          {isActive ? 'ğŸ“· åœæ­¢æ”å½±æ©Ÿ' : 'ğŸ“· å•Ÿå‹•æ”å½±æ©Ÿ'}
        </button>
        
        {isProcessing && (
          <div className="processing-indicator">
            <div className="spinner"></div>
            <span>è™•ç†ä¸­...</span>
          </div>
        )}
      </div>

      {error && (
        <div className="error-message">
          <p>âš ï¸ {error}</p>
          <button onClick={initializeCamera}>é‡è©¦</button>
        </div>
      )}

      <div className="camera-preview">
        <video
          ref={videoRef}
          autoPlay
          playsInline
          muted
          className="video-preview"
          style={{ display: isActive ? 'block' : 'none' }}
        />
        
        <canvas
          ref={canvasRef}
          className="processing-canvas"
          style={{ display: isActive ? 'block' : 'none' }}
        />
        
        {!isActive && (
          <div className="camera-placeholder">
            <div className="placeholder-icon">ğŸ“·</div>
            <p>é»æ“Šä¸Šæ–¹æŒ‰éˆ•å•Ÿå‹•æ”å½±æ©Ÿ</p>
            <small>éœ€è¦æ”å½±æ©Ÿæ¬Šé™ä»¥é€²è¡ŒRGBæª¢æ¸¬</small>
          </div>
        )}
      </div>

      <div className="camera-info">
        <p>ğŸ’¡ å°‡æ”å½±æ©Ÿå°æº–ç‡ˆç æˆ–è‰²å…‰å€åŸŸé€²è¡Œæª¢æ¸¬</p>
        <p>ğŸ” ç³»çµ±æœƒè‡ªå‹•è­˜åˆ¥é‚Šç·£å’Œè‰²å…‰å€å¡Š</p>
        <div className="motion-sensitivity">
          <label>ç•«é¢è®Šå‹•æ•æ„Ÿåº¦:</label>
          <input
            type="range"
            min="0.01"
            max="0.5"
            step="0.01"
            value={frameChangeThreshold.current}
            onChange={(e) => {
              frameChangeThreshold.current = parseFloat(e.target.value);
              log('ğŸ›ï¸ æ•æ„Ÿåº¦èª¿æ•´ç‚º:', (frameChangeThreshold.current * 100).toFixed(1) + '%');
            }}
          />
          <span>{(frameChangeThreshold.current * 100).toFixed(1)}%</span>
        </div>
      </div>
    </div>
  );
};

export default CameraCapture;
