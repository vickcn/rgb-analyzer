#!/usr/bin/env python3
"""
è‰²å…‰åˆ†é¡å™¨è¨“ç·´è…³æœ¬
ä½¿ç”¨ç¾æœ‰è³‡æ–™ä½œç‚ºæ ¸å¿ƒåŸºæº–ï¼Œè¨“ç·´åˆ†é¡å™¨ç”¨æ–¼è­˜åˆ¥æ–°çš„è‰²å…‰æ¨£æœ¬
"""

import pandas as pd
import numpy as np
import json
from pathlib import Path
import re
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import joblib

def load_training_data(excel_path):
    """è¼‰å…¥è¨“ç·´æ•¸æ“š"""
    df = pd.read_excel(excel_path)
    
    # å¾åœ–ç‰‡åç¨±æå–çœŸå¯¦æ¨™ç±¤
    true_labels = []
    for filename in df["åœ–ç‰‡åç¨±"]:
        clean_name = re.sub(r'\d+$', '', filename.replace('.png', ''))
        true_labels.append(clean_name)
    
    df['True_Label'] = true_labels
    
    return df

def prepare_features(df, feature_columns=None):
    """æº–å‚™ç‰¹å¾µå’Œæ¨™ç±¤"""
    if feature_columns is None:
        feature_columns = ["R", "G", "B", "H (è‰²ç›¸)", "S (é£½å’Œåº¦)", "V (æ˜åº¦)", "è‰²æº« (K)"]
    
    # æå–ç‰¹å¾µ
    X = df[feature_columns].copy()
    X = X.fillna(X.mean())
    
    # æå–æ¨™ç±¤ï¼ˆå¾åœ–ç‰‡åç¨±ï¼‰
    y = df['True_Label'].values
    
    return X, y, feature_columns

def train_classifiers(X, y, test_size=0.15):
    """è¨“ç·´å¤šç¨®åˆ†é¡å™¨"""
    
    print("âš ï¸  å°æ–¼å°æ¨£æœ¬æƒ…æ³ï¼Œèª¿æ•´åˆ†å‰²æ¯”ä¾‹")
    
    # ç°¡å–®åˆ†å‰²ï¼ˆä¸ä½¿ç”¨ stratifyï¼‰
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)
    
    # æ¨™æº–åŒ–
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # æœªæ¨™æº–åŒ–çš„æ•¸æ“šï¼ˆç”¨æ–¼æŸäº›ç®—æ³•ï¼‰
    X_train_raw = X_train.values
    X_test_raw = X_test.values
    
    classifiers = {
        'KNN': KNeighborsClassifier(n_neighbors=3, weights='distance'),
        'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10),
        'SVM': SVC(kernel='rbf', C=1.0, gamma='scale', probability=True)
    }
    
    results = {}
    
    print("ğŸ¤– è¨“ç·´åˆ†é¡å™¨...")
    print(f"ğŸ“Š è¨“ç·´é›†: {len(X_train)} ç­†")
    print(f"ğŸ“Š æ¸¬è©¦é›†: {len(X_test)} ç­†\n")
    
    # è¨“ç·´æ¯å€‹åˆ†é¡å™¨
    for name, clf in classifiers.items():
        print(f"è¨“ç·´ {name}...")
        
        # KNN ä½¿ç”¨æ¨™æº–åŒ–æ•¸æ“šï¼ŒRF ä½¿ç”¨åŸå§‹æ•¸æ“š
        if name == 'KNN':
            clf.fit(X_train_scaled, y_train)
            y_pred = clf.predict(X_test_scaled)
            y_pred_proba = clf.predict_proba(X_test_scaled)
        elif name == 'SVM':
            clf.fit(X_train_scaled, y_train)
            y_pred = clf.predict(X_test_scaled)
            y_pred_proba = clf.predict_proba(X_test_scaled)
        else:  # RandomForest
            clf.fit(X_train_raw, y_train)
            y_pred = clf.predict(X_test_raw)
            y_pred_proba = clf.predict_proba(X_test_raw)
        
        # è©•ä¼°
        accuracy = accuracy_score(y_test, y_pred)
        
        results[name] = {
            'classifier': clf,
            'accuracy': accuracy,
            'y_pred': y_pred,
            'y_test': y_test,
            'scaler': scaler if name in ['KNN', 'SVM'] else None,
            'feature_columns': feature_columns,
            'probabilities': y_pred_proba
        }
        
        print(f"âœ“ {name} - æº–ç¢ºç‡: {accuracy:.3f}")
        print(f"  åˆ†é¡å ±å‘Š:")
        print(classification_report(y_test, y_pred))
        print()
    
    return results, X_test, y_test

def predict_new_samples(classifier, scaler, feature_columns, new_data):
    """
    é æ¸¬æ–°æ¨£æœ¬
    
    Args:
        classifier: è¨“ç·´å¥½çš„åˆ†é¡å™¨
        scaler: æ¨™æº–åŒ–å™¨ï¼ˆå¦‚æœéœ€è¦çš„è©±ï¼‰
        feature_columns: ç‰¹å¾µæ¬„ä½åˆ—è¡¨
        new_data: æ–°æ¨£æœ¬çš„ RGB, HSV, è‰²æº«ç­‰ç‰¹å¾µ
    
    Returns:
        prediction: é æ¸¬çš„é¡åˆ¥
        probabilities: å„é¡åˆ¥çš„æ©Ÿç‡
    """
    # æº–å‚™æ–°æ•¸æ“š
    new_df = pd.DataFrame([new_data], columns=feature_columns)
    
    # å¦‚æœéœ€è¦æ¨™æº–åŒ–
    if scaler is not None:
        new_scaled = scaler.transform(new_df)
        prediction = classifier.predict(new_scaled)
        probabilities = classifier.predict_proba(new_scaled)
    else:
        prediction = classifier.predict(new_df.values)
        probabilities = classifier.predict_proba(new_df.values)
    
    # ç²å–é¡åˆ¥æ¨™ç±¤
    classes = classifier.classes_
    
    # çµ„åˆé¡åˆ¥å’Œæ©Ÿç‡
    result = {
        'prediction': prediction[0],
        'confidence': max(probabilities[0]),
        'all_probabilities': {class_name: prob for class_name, prob in zip(classes, probabilities[0])}
    }
    
    return result

def save_models(results, output_dir):
    """å„²å­˜è¨“ç·´å¥½çš„æ¨¡å‹"""
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"ğŸ’¾ å„²å­˜æ¨¡å‹åˆ°: {output_dir}")
    
    for name, result in results.items():
        # å„²å­˜åˆ†é¡å™¨
        clf_file = output_dir / f"classifier_{name.lower()}.joblib"
        joblib.dump(result['classifier'], clf_file)
        print(f"   â€¢ {clf_file.name}")
        
        # å„²å­˜ scalerï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰
        if result['scaler'] is not None:
            scaler_file = output_dir / f"scaler_{name.lower()}.joblib"
            joblib.dump(result['scaler'], scaler_file)
            print(f"   â€¢ {scaler_file.name}")
        
        # å„²å­˜é…ç½®
        config_file = output_dir / f"config_{name.lower()}.json"
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump({
                'model_type': name,
                'accuracy': result['accuracy'],
                'feature_columns': result['feature_columns']
            }, f, ensure_ascii=False, indent=2)
        print(f"   â€¢ {config_file.name}")

def main():
    """ä¸»ç¨‹å¼"""
    # æª”æ¡ˆè·¯å¾‘
    excel_path = Path("output/color_analysis_result_numeric.xlsx")
    
    if not excel_path.exists():
        print(f"âŒ æª”æ¡ˆä¸å­˜åœ¨: {excel_path}")
        print(f"ğŸ’¡ è«‹å…ˆåŸ·è¡Œ color_classification_validator.py å’Œ clean_excel_columns.py")
        return
    
    # è¼‰å…¥æ•¸æ“š
    print("ğŸ“‚ è¼‰å…¥è¨“ç·´æ•¸æ“š...")
    df = load_training_data(excel_path)
    
    classes = df['True_Label'].unique()
    print(f"âœ… è¼‰å…¥ {len(df)} ç­†æ•¸æ“š")
    print(f"ğŸ·ï¸  æ¨™ç±¤é¡åˆ¥ ({len(classes)} å€‹): {list(classes)}")
    
    # æº–å‚™ç‰¹å¾µ
    feature_columns = ["R", "G", "B", "H (è‰²ç›¸)", "S (é£½å’Œåº¦)", "V (æ˜åº¦)", "è‰²æº« (K)"]
    X, y, _ = prepare_features(df, feature_columns)
    
    print(f"ğŸ¯ ä½¿ç”¨ç‰¹å¾µ: {feature_columns}\n")
    
    # è¨“ç·´åˆ†é¡å™¨
    results, X_test, y_test = train_classifiers(X, y)
    
    # å„²å­˜æ¨¡å‹
    output_dir = "output/trained_models"
    save_models(results, output_dir)
    
    # é¸æ“‡æœ€ä½³æ¨¡å‹
    best_model_name = max(results, key=lambda x: results[x]['accuracy'])
    print(f"\nğŸ† æœ€ä½³æ¨¡å‹: {best_model_name} (æº–ç¢ºç‡: {results[best_model_name]['accuracy']:.3f})")
    
    # å„²å­˜æ¨¡å‹ä½¿ç”¨èªªæ˜
    readme_file = Path(output_dir) / "README.md"
    with open(readme_file, 'w', encoding='utf-8') as f:
        f.write(f"""# è‰²å…‰åˆ†é¡æ¨¡å‹ä½¿ç”¨èªªæ˜

## æœ€ä½³æ¨¡å‹: {best_model_name}
æº–ç¢ºç‡: {results[best_model_name]['accuracy']:.3f}

## è¼‰å…¥æ¨¡å‹

```python
import joblib

# è¼‰å…¥åˆ†é¡å™¨å’Œ scaler
classifier = joblib.load('classifier_{best_model_name.lower()}.joblib')
scaler = joblib.load('scaler_{best_model_name.lower()}.joblib')  # å¦‚æœéœ€è¦

# æº–å‚™æ–°æ¨£æœ¬çš„ç‰¹å¾µ
new_sample = {{
    'R': 100,
    'G': 150,
    'B': 200,
    'H (è‰²ç›¸)': 210,
    'S (é£½å’Œåº¦)': 50,
    'V (æ˜åº¦)': 75,
    'è‰²æº« (K)': 6500
}}

# é æ¸¬
features = [new_sample[col] for col in feature_columns]
if scaler:
    features_scaled = scaler.transform([features])
    prediction = classifier.predict(features_scaled)
    probabilities = classifier.predict_proba(features_scaled)
else:
    prediction = classifier.predict([features])
    probabilities = classifier.predict_proba([features])

print(f"é æ¸¬é¡åˆ¥: {{prediction[0]}}")
print(f"ä¿¡å¿ƒåº¦: {{max(probabilities[0]):.3f}}")
```

## ç‰¹å¾µæ¬„ä½
{feature_columns}
""")
    
    print(f"\nâœ… æ¨¡å‹å·²å„²å­˜è‡³: {output_dir}")
    print(f"ğŸ“š ä½¿ç”¨èªªæ˜: {readme_file}")

if __name__ == "__main__":
    main()
