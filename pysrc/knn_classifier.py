#!/usr/bin/env python3
"""
K-NN è‰²å…‰åˆ†é¡å™¨
ä½¿ç”¨ç¾æœ‰è³‡æ–™ä½œç‚ºåŸºæº–ï¼Œå°æ–°æ¨£æœ¬é€²è¡Œåˆ†é¡
"""

import pandas as pd
import numpy as np
import json
from pathlib import Path
import re
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, confusion_matrix
import joblib

def load_training_data(excel_path):
    """è¼‰å…¥è¨“ç·´æ•¸æ“š"""
    df = pd.read_excel(excel_path)
    
    # å¾åœ–ç‰‡åç¨±æå–çœŸå¯¦æ¨™ç±¤
    true_labels = []
    for filename in df["åœ–ç‰‡åç¨±"]:
        clean_name = re.sub(r'\d+$', '', filename.replace('.png', ''))
        true_labels.append(clean_name)
    
    df['True_Label'] = true_labels
    
    return df

def prepare_data(df):
    """æº–å‚™ç‰¹å¾µå’Œæ¨™ç±¤"""
    feature_columns = ["R", "G", "B", "H (è‰²ç›¸)", "S (é£½å’Œåº¦)", "V (æ˜åº¦)", "è‰²æº« (K)"]
    
    # æå–ç‰¹å¾µ
    X = df[feature_columns].copy()
    X = X.fillna(X.mean())
    
    # æå–æ¨™ç±¤
    y = df['True_Label'].values
    
    return X, y, feature_columns

def train_knn(X, y, feature_columns, k=3):
    """
    è¨“ç·´ K-NN åˆ†é¡å™¨
    
    Args:
        X: ç‰¹å¾µæ•¸æ“š
        y: æ¨™ç±¤
        feature_columns: ç‰¹å¾µæ¬„ä½åˆ—è¡¨
        k: æœ€è¿‘çš„ k å€‹é„°å±…
    """
    print(f"ğŸ¤– è¨“ç·´ K-NN (k={k})...")
    print(f"ğŸ“Š è¨“ç·´æ¨£æœ¬æ•¸: {len(X)}")
    print(f"ğŸ·ï¸  é¡åˆ¥æ•¸: {len(np.unique(y))}")
    
    # æ¨™æº–åŒ–ç‰¹å¾µï¼ˆK-NN éœ€è¦æ¨™æº–åŒ–ï¼‰
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # è¨“ç·´ K-NN
    knn = KNeighborsClassifier(n_neighbors=k, weights='distance', metric='euclidean')
    knn.fit(X_scaled, y)
    
    # è©•ä¼°ï¼ˆä½¿ç”¨å…¨éƒ¨æ•¸æ“šä½œç‚ºè¨“ç·´é›†è©•ä¼°ï¼‰
    y_pred = knn.predict(X_scaled)
    
    print(f"\nğŸ“Š è¨“ç·´é›†æº–ç¢ºç‡è©•ä¼°:")
    print(classification_report(y, y_pred))
    
    return knn, scaler, feature_columns

def save_model(knn, scaler, feature_columns, output_dir):
    """å„²å­˜æ¨¡å‹"""
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # å„²å­˜åˆ†é¡å™¨
    knn_file = output_dir / "knn_classifier.joblib"
    joblib.dump(knn, knn_file)
    print(f"ğŸ’¾ å„²å­˜åˆ†é¡å™¨: {knn_file}")
    
    # å„²å­˜ scaler
    scaler_file = output_dir / "knn_scaler.joblib"
    joblib.dump(scaler, scaler_file)
    print(f"ğŸ’¾ å„²å­˜æ¨™æº–åŒ–å™¨: {scaler_file}")
    
    # å„²å­˜é…ç½®
    config = {
        'model_type': 'K-NN',
        'feature_columns': feature_columns,
        'k': knn.n_neighbors,
        'distance_metric': 'euclidean',
        'weights': 'distance'
    }
    
    config_file = output_dir / "knn_config.json"
    with open(config_file, 'w', encoding='utf-8') as f:
        json.dump(config, f, ensure_ascii=False, indent=2)
    print(f"ğŸ’¾ å„²å­˜é…ç½®: {config_file}")
    
    return config_file

def main():
    """ä¸»ç¨‹å¼"""
    # æª”æ¡ˆè·¯å¾‘
    excel_path = Path("output/color_analysis_result_numeric.xlsx")
    
    if not excel_path.exists():
        print(f"âŒ æª”æ¡ˆä¸å­˜åœ¨: {excel_path}")
        print(f"ğŸ’¡ è«‹å…ˆåŸ·è¡Œ color_classification_validator.py å’Œ clean_excel_columns.py")
        return
    
    # è¼‰å…¥æ•¸æ“š
    print("ğŸ“‚ è¼‰å…¥è¨“ç·´æ•¸æ“š...")
    df = load_training_data(excel_path)
    
    classes = sorted(df['True_Label'].unique())
    print(f"âœ… è¼‰å…¥ {len(df)} ç­†æ•¸æ“š")
    print(f"ğŸ·ï¸  æ¨™ç±¤é¡åˆ¥ ({len(classes)} å€‹):")
    for i, cls in enumerate(classes, 1):
        count = len(df[df['True_Label'] == cls])
        print(f"   {i:2d}. {cls} ({count} ç­†)")
    
    # æº–å‚™æ•¸æ“š
    X, y, feature_columns = prepare_data(df)
    
    print(f"\nğŸ¯ ä½¿ç”¨ç‰¹å¾µ ({len(feature_columns)} å€‹):")
    for col in feature_columns:
        print(f"   â€¢ {col}")
    
    print()
    
    # è¨“ç·´ K-NN
    knn, scaler, _ = train_knn(X, y, feature_columns, k=3)
    
    # å„²å­˜æ¨¡å‹
    output_dir = "output/knn_model"
    config_file = save_model(knn, scaler, feature_columns, output_dir)
    
    # è®€å–é…ç½®
    with open(config_file, 'r', encoding='utf-8') as f:
        config = json.load(f)
    
    print(f"\nâœ… K-NN æ¨¡å‹è¨“ç·´å®Œæˆï¼")
    print(f"\nğŸ’¡ ä½¿ç”¨æ–¹å¼:")
    print(f"""
# è¼‰å…¥æ¨¡å‹
import joblib

knn = joblib.load('{config_file.parent}/knn_classifier.joblib')
scaler = joblib.load('{config_file.parent}/knn_scaler.joblib')

# æº–å‚™æ–°æ¨£æœ¬
new_sample = [
    100,   # R
    150,   # G
    200,   # B
    210,   # H (è‰²ç›¸)
    50,    # S (é£½å’Œåº¦)
    75,    # V (æ˜åº¦)
    6500   # è‰²æº« (K)
]

# æ¨™æº–åŒ–
new_sample_scaled = scaler.transform([new_sample])

# é æ¸¬
prediction = knn.predict(new_sample_scaled)
probabilities = knn.predict_proba(new_sample_scaled)

print(f"é æ¸¬é¡åˆ¥: {{prediction[0]}}")
print(f"ä¿¡å¿ƒåº¦: {{max(probabilities[0]):.3f}}")

# æŸ¥çœ‹æ‰€æœ‰é¡åˆ¥çš„æ©Ÿç‡ï¼ˆæŒ‰æ©Ÿç‡æ’åºï¼‰
classes = knn.classes_
probs = probabilities[0]
sorted_results = sorted(zip(classes, probs), key=lambda x: x[1], reverse=True)

print(f"æ‰€æœ‰å¯èƒ½çš„é¡åˆ¥:")
for cls, prob in sorted_results[:5]:  # é¡¯ç¤ºå‰5å€‹
    print(f"  {{cls}}: {{prob:.3f}}")
""")
    
    print(f"\nğŸ“ æ¨¡å‹æª”æ¡ˆä½ç½®: {output_dir}")

if __name__ == "__main__":
    main()
